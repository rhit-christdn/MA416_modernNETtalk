{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d90a372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 135166 dictionary entries (words).\n",
      "Characters: 32  Phones: 40\n",
      "Sample phones: ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH', 'IY', 'JH', 'K']\n",
      "Split: train 118947  dev 2703  test 13516\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training loss: 1.0312\n",
      "Dev PER: 24.65%  WER: 79.17%\n",
      "Saved best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 training loss: 0.8175\n",
      "Dev PER: 23.13%  WER: 74.51%\n",
      "Saved best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 training loss: 0.7688\n",
      "Dev PER: 21.97%  WER: 73.99%\n",
      "Saved best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 training loss: 0.7446\n",
      "Dev PER: 21.55%  WER: 72.59%\n",
      "Saved best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 training loss: 0.7281\n",
      "Dev PER: 21.31%  WER: 71.66%\n",
      "Saved best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 training loss: 0.7163\n",
      "Dev PER: 20.99%  WER: 72.33%\n",
      "Saved best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 training loss: 0.7066\n",
      "Dev PER: 20.80%  WER: 70.55%\n",
      "Saved best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 training loss: 0.6997\n",
      "Dev PER: 20.89%  WER: 72.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 training loss: 0.6934\n",
      "Dev PER: 20.81%  WER: 72.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 training loss: 0.6886\n",
      "Dev PER: 20.15%  WER: 68.78%\n",
      "Saved best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 training loss: 0.6841\n",
      "Dev PER: 20.40%  WER: 70.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 training loss: 0.6801\n",
      "Dev PER: 20.53%  WER: 70.37%\n",
      "Test PER: 20.62%  WER: 71.46%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "g2p_nettalk_zero_delay.py\n",
    "\n",
    "Nettalk-style grapheme-to-phoneme (G2P) training with:\n",
    "- Zero-delay alignment (pad phoneme seq with φ so output length == grapheme length)\n",
    "- ARPAbet tokens (optionally strip stress digits)\n",
    "- Fixed context window size = 7 (3 left, center, 3 right)\n",
    "- PyTorch feed-forward neural network (embedding -> hidden -> softmax)\n",
    "\n",
    "Usage:\n",
    "    python g2p_nettalk_zero_delay.py\n",
    "\n",
    "Requires:\n",
    "    - Python 3.8+\n",
    "    - PyTorch\n",
    "    - tqdm (optional)\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import random\n",
    "import argparse\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------------------------\n",
    "# Config / hyperparameters\n",
    "# ---------------------------\n",
    "WINDOW = 7               # Nettalk context window (odd)\n",
    "LEFT_CTX = RIGHT_CTX = (WINDOW - 1) // 2\n",
    "EMBED_DIM = 32\n",
    "HIDDEN_DIM = 256\n",
    "BATCH_SIZE = 256\n",
    "LR = 1e-3\n",
    "EPOCHS = 12\n",
    "MAX_WORDS = None         # optionally limit number of words loaded for quick debug (None -> all)\n",
    "STRIP_STRESS = True      # strip numeric stress markers from ARPAbet phones (AH0 -> AH)\n",
    "PAD_GRAP = '<pad_g>'     # grapheme pad for context window\n",
    "PAD_PHON = 'φ'           # zero-delay padding symbol for phoneme sequence (phi)\n",
    "START_SYM = '<s>'\n",
    "END_SYM = '</s>'\n",
    "\n",
    "CMU_DICT_PATH = 'cmudict.dict.txt'\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities: load CMUDict\n",
    "# ---------------------------\n",
    "def load_cmudict(path: str, max_words=None) -> List[Tuple[str, List[str]]]:\n",
    "    \"\"\"\n",
    "    Returns list of tuples (word, phoneme_list)\n",
    "    Strips CMUDict comment lines beginning with ';;;'\n",
    "    Strips variant numbers from words like 'WORD(1)' -> 'WORD'\n",
    "    \"\"\"\n",
    "    entries = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or line.startswith(';;;'):\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            word_raw = parts[0]\n",
    "            # remove variant numbering (e.g., WORD(1) -> WORD)\n",
    "            word = re.sub(r'\\(\\d+\\)$', '', word_raw).lower()\n",
    "            phones = parts[1:]\n",
    "            if STRIP_STRESS:\n",
    "                phones = [re.sub(r'\\d+$', '', p) for p in phones]\n",
    "            entries.append((word, phones))\n",
    "            if max_words and len(entries) >= max_words:\n",
    "                break\n",
    "    return entries\n",
    "\n",
    "# ---------------------------\n",
    "# Zero-delay alignment\n",
    "# ---------------------------\n",
    "def zero_delay_align(graphemes: List[str], phonemes: List[str], pad_phi: str = PAD_PHON) -> List[str]:\n",
    "    \"\"\"\n",
    "    Implements zero-delay alignment: produce an output phoneme sequence\n",
    "    whose length equals number of graphemes by padding phoneme sequence\n",
    "    at the end with pad_phi. If there are more phonemes than graphemes,\n",
    "    we truncate (rare).\n",
    "    Example:\n",
    "        graphemes = ['g','o','o','g','l','e']\n",
    "        phonemes  = ['g','u','g','@','l']  -> pad with φ -> 6 outputs\n",
    "        result    = ['g','u','g','@','l','φ']\n",
    "    \"\"\"\n",
    "    if len(phonemes) <= len(graphemes):\n",
    "        out = phonemes + [pad_phi] * (len(graphemes) - len(phonemes))\n",
    "    else:\n",
    "        # truncate extra phonemes (rare); alternative: collapse multiple phonemes per grapheme with more complex alignment\n",
    "        out = phonemes[:len(graphemes)]\n",
    "    return out\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset creation (per-glyph training examples)\n",
    "# ---------------------------\n",
    "class G2PDataset(Dataset):\n",
    "    def __init__(self, word_phone_pairs, char2idx, phone2idx, window=WINDOW):\n",
    "        self.window = window\n",
    "        self.left = (window - 1) // 2\n",
    "        self.char2idx = char2idx\n",
    "        self.phone2idx = phone2idx\n",
    "        self.examples = []  # list of (context_indices_tensor, target_phone_idx, word_idx, position_in_word)\n",
    "        for w_idx, (word, phones) in enumerate(word_phone_pairs):\n",
    "            grap = list(word)  # characters\n",
    "            # optionally add start/end markers to grapheme seq so net can see boundaries\n",
    "            grap_padded = [START_SYM] * self.left + grap + [END_SYM] * self.left\n",
    "            # zero-delay align phonemes to graphemes (no start/end) -> length equals len(grap)\n",
    "            aligned_phones = zero_delay_align(graphemes=grap, phonemes=phones, pad_phi=PAD_PHON)\n",
    "            # for each position in the grapheme sequence, create a window and target\n",
    "            for pos in range(len(grap)):\n",
    "                # window centered at pos within original grap (not including padded START/END used above)\n",
    "                left_idx = pos\n",
    "                window_chars = grap_padded[left_idx:left_idx + self.window]\n",
    "                # convert to indices\n",
    "                context_idxs = [char2idx.get(ch, char2idx[PAD_GRAP]) for ch in window_chars]\n",
    "                target_phone = aligned_phones[pos]\n",
    "                target_idx = phone2idx[target_phone]\n",
    "                # store (list of ints) and target\n",
    "                self.examples.append((context_idxs, target_idx, w_idx, pos))\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    def __getitem__(self, idx):\n",
    "        ctx, tgt, widx, pos = self.examples[idx]\n",
    "        return torch.tensor(ctx, dtype=torch.long), torch.tensor(tgt, dtype=torch.long), widx, pos\n",
    "\n",
    "# ---------------------------\n",
    "# Model\n",
    "# ---------------------------\n",
    "class NettalkModel(nn.Module):\n",
    "    def __init__(self, n_chars, embed_dim, window, hidden_dim, n_phones, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.window = window\n",
    "        self.embed = nn.Embedding(n_chars, embed_dim, padding_idx=None)\n",
    "        self.fc1 = nn.Linear(embed_dim * window, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, n_phones)\n",
    "    def forward(self, x):  # x: (B, window) long\n",
    "        emb = self.embed(x)              # (B, window, embed_dim)\n",
    "        flat = emb.view(emb.size(0), -1) # (B, window*embed_dim)\n",
    "        h = self.dropout(self.relu(self.fc1(flat)))\n",
    "        out = self.fc2(h)                # logits (B, n_phones)\n",
    "        return out\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers: vocab build, evaluation\n",
    "# ---------------------------\n",
    "def build_vocabs(entries):\n",
    "    # chars: lowercase letters a-z, apostrophe, and special PAD/START/END\n",
    "    char_counter = Counter()\n",
    "    phone_counter = Counter()\n",
    "    for word, phones in entries:\n",
    "        for ch in word:\n",
    "            char_counter[ch] += 1\n",
    "        for p in phones:\n",
    "            phone_counter[p] += 1\n",
    "    # char->idx (reserve small indices for PAD, start/end)\n",
    "    chars = [PAD_GRAP, START_SYM, END_SYM] + sorted([c for c in char_counter])\n",
    "    char2idx = {c: i for i, c in enumerate(chars)}\n",
    "    idx2char = {i: c for c, i in char2idx.items()}\n",
    "    # phones: include PAD_PHON (phi) if not present\n",
    "    phones = sorted(set(list(phone_counter.keys()) + [PAD_PHON]))\n",
    "    phone2idx = {p: i for i, p in enumerate(phones)}\n",
    "    idx2phone = {i: p for p, i in phone2idx.items()}\n",
    "    return char2idx, idx2char, phone2idx, idx2phone\n",
    "\n",
    "def compute_word_level_errors(model, dataset, idx2phone, entries, device):\n",
    "    \"\"\"\n",
    "    Reconstruct predicted phoneme sequence per word (by collecting per-position predictions),\n",
    "    then compute simple PER and WER (word considered error if any phoneme differs or a phone missing).\n",
    "    This treats the phi pad as normal symbol: when the true phone is phi it means no real phone at that grapheme.\n",
    "    Returns: (phoneme_error_rate, word_error_rate)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # prepare containers\n",
    "    word_preds = dict()  # widx -> list of preds per position (length = word length)\n",
    "    word_trues = dict()\n",
    "    # initialize\n",
    "    for i, (w, phones) in enumerate(entries):\n",
    "        word_trues[i] = zero_delay_align(list(w), phones, pad_phi=PAD_PHON)\n",
    "        word_preds[i] = [''] * len(w)\n",
    "    loader = DataLoader(dataset, batch_size=1024, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            ctx, tgt, widxs, poss = batch\n",
    "            ctx = ctx.to(device)\n",
    "            logits = model(ctx)\n",
    "            preds = logits.argmax(dim=1).cpu().tolist()\n",
    "            for p_idx, widx, pos in zip(preds, widxs.tolist(), poss.tolist()):\n",
    "                phone_pred = idx2phone[p_idx]\n",
    "                word_preds[widx][pos] = phone_pred\n",
    "    # compute PER and WER\n",
    "    total_phonemes = 0\n",
    "    phone_errors = 0\n",
    "    total_words = len(entries)\n",
    "    word_errors = 0\n",
    "    for i in range(len(entries)):\n",
    "        true_seq = word_trues[i]\n",
    "        pred_seq = word_preds[i]\n",
    "        # phoneme-level edit distance (simple Levenshtein)\n",
    "        # compute substitutions/insertions/deletions between true_seq and pred_seq\n",
    "        # we'll compute exact sequence edit distance:\n",
    "        a = true_seq\n",
    "        b = pred_seq\n",
    "        n, m = len(a), len(b)\n",
    "        # dp\n",
    "        dp = [[0]*(m+1) for _ in range(n+1)]\n",
    "        for ii in range(n+1):\n",
    "            dp[ii][0] = ii\n",
    "        for jj in range(m+1):\n",
    "            dp[0][jj] = jj\n",
    "        for ii in range(1, n+1):\n",
    "            for jj in range(1, m+1):\n",
    "                cost = 0 if a[ii-1] == b[jj-1] else 1\n",
    "                dp[ii][jj] = min(dp[ii-1][jj] + 1,     # deletion\n",
    "                                 dp[ii][jj-1] + 1,     # insertion\n",
    "                                 dp[ii-1][jj-1] + cost) # substitution\n",
    "        ed = dp[n][m]\n",
    "        phone_errors += ed\n",
    "        total_phonemes += n\n",
    "        if ed > 0:\n",
    "            word_errors += 1\n",
    "    per = phone_errors / total_phonemes if total_phonemes > 0 else 0.0\n",
    "    wer = word_errors / total_words if total_words > 0 else 0.0\n",
    "    return per, wer\n",
    "\n",
    "# ---------------------------\n",
    "# Training routine\n",
    "# ---------------------------\n",
    "def train():\n",
    "    # load data\n",
    "    entries = load_cmudict(CMU_DICT_PATH, max_words=MAX_WORDS)\n",
    "    print(f\"Loaded {len(entries)} dictionary entries (words).\")\n",
    "\n",
    "    # build vocabs\n",
    "    char2idx, idx2char, phone2idx, idx2phone = build_vocabs(entries)\n",
    "    print(f\"Characters: {len(char2idx)}  Phones: {len(phone2idx)}\")\n",
    "    print(\"Sample phones:\", list(phone2idx.keys())[:20])\n",
    "\n",
    "    # shuffle and split words into train/dev/test (by words)\n",
    "    random.seed(42)\n",
    "    indices = list(range(len(entries)))\n",
    "    random.shuffle(indices)\n",
    "    n = len(indices)\n",
    "    n_dev = int(0.02 * n)    # 2% dev\n",
    "    n_test = int(0.10 * n)   # 10% test\n",
    "    dev_idx = indices[:n_dev]\n",
    "    test_idx = indices[n_dev:n_dev + n_test]\n",
    "    train_idx = indices[n_dev + n_test:]\n",
    "    train_pairs = [entries[i] for i in train_idx]\n",
    "    dev_pairs = [entries[i] for i in dev_idx]\n",
    "    test_pairs = [entries[i] for i in test_idx]\n",
    "    print(f\"Split: train {len(train_pairs)}  dev {len(dev_pairs)}  test {len(test_pairs)}\")\n",
    "\n",
    "    # create datasets\n",
    "    train_ds = G2PDataset(train_pairs, char2idx, phone2idx, window=WINDOW)\n",
    "    dev_ds   = G2PDataset(dev_pairs, char2idx, phone2idx, window=WINDOW)\n",
    "    test_ds  = G2PDataset(test_pairs, char2idx, phone2idx, window=WINDOW)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    dev_loader   = DataLoader(dev_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    model = NettalkModel(n_chars=len(char2idx), embed_dim=EMBED_DIM, window=WINDOW,\n",
    "                         hidden_dim=HIDDEN_DIM, n_phones=len(phone2idx)).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    # training loop\n",
    "    best_dev_per = 1.0\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_examples = 0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False)\n",
    "        for batch in pbar:\n",
    "            ctx, tgt, _, _ = batch\n",
    "            ctx = ctx.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(ctx)   # (B, n_phones)\n",
    "            loss = criterion(logits, tgt)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * ctx.size(0)\n",
    "            total_examples += ctx.size(0)\n",
    "            pbar.set_postfix(loss=total_loss/total_examples)\n",
    "        avg_loss = total_loss / total_examples\n",
    "        print(f\"Epoch {epoch} training loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # dev evaluation: phoneme accuracy and PER/WER\n",
    "        dev_per, dev_wer = compute_word_level_errors(model, dev_ds, idx2phone, dev_pairs, device)\n",
    "        print(f\"Dev PER: {dev_per*100:.2f}%  WER: {dev_wer*100:.2f}%\")\n",
    "\n",
    "        if dev_per < best_dev_per:\n",
    "            best_dev_per = dev_per\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'char2idx': char2idx,\n",
    "                'phone2idx': phone2idx,\n",
    "                'idx2phone': idx2phone,\n",
    "                'idx2char': idx2char,\n",
    "            }, 'best_nettalk_zero_delay.pth')\n",
    "            print(\"Saved best model.\")\n",
    "\n",
    "    # final test evaluation\n",
    "    checkpoint = torch.load('best_nettalk_zero_delay.pth', map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    test_per, test_wer = compute_word_level_errors(model, test_ds, checkpoint['idx2phone'], test_pairs, device)\n",
    "    print(f\"Test PER: {test_per*100:.2f}%  WER: {test_wer*100:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb4a3ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      google → G UW G AH L L\n",
      "     physics → F IH Z IH K K S\n",
      "     chatgpt → CH AE T G P T φ\n",
      "   algorithm → AE L G ER TH DH TH M φ\n",
      "        data → D AA T AH\n",
      "google: G UW G AH L\n",
      "physics: F IH Z IH K S\n",
      "algorithm: AE L G ER IH DH AH M\n",
      "data: D AE T AH\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Test trained Nettalk G2P model\n",
    "# ==============================\n",
    "\n",
    "import torch\n",
    "\n",
    "# Load model + mappings\n",
    "checkpoint = torch.load('best_nettalk_zero_delay.pth', map_location='cpu')\n",
    "char2idx = checkpoint['char2idx']\n",
    "idx2char = checkpoint['idx2char']\n",
    "phone2idx = checkpoint['phone2idx']\n",
    "idx2phone = checkpoint['idx2phone']\n",
    "\n",
    "# Rebuild model\n",
    "model = NettalkModel(\n",
    "    n_chars=len(char2idx),\n",
    "    embed_dim=EMBED_DIM,\n",
    "    window=WINDOW,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    n_phones=len(phone2idx)\n",
    ")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# helper functions\n",
    "def predict_word(word: str):\n",
    "    \"\"\"Predict phoneme sequence for a single word (zero-delay context window).\"\"\"\n",
    "    word = word.lower()\n",
    "    graphemes = list(word)\n",
    "    # pad with start/end symbols for context\n",
    "    padded = [START_SYM]*LEFT_CTX + graphemes + [END_SYM]*RIGHT_CTX\n",
    "    preds = []\n",
    "    for i in range(len(graphemes)):\n",
    "        window_chars = padded[i : i + WINDOW]\n",
    "        ctx_idx = torch.tensor(\n",
    "            [char2idx.get(ch, char2idx[PAD_GRAP]) for ch in window_chars],\n",
    "            dtype=torch.long\n",
    "        ).unsqueeze(0)  # (1, window)\n",
    "        with torch.no_grad():\n",
    "            logits = model(ctx_idx)\n",
    "            pred_idx = logits.argmax(dim=1).item()\n",
    "        pred_phone = idx2phone[pred_idx]\n",
    "        preds.append(pred_phone)\n",
    "    return preds\n",
    "\n",
    "# test words from CMUdict (examples)\n",
    "test_words = [\"google\", \"physics\", \"chatgpt\", \"algorithm\", \"data\"]\n",
    "\n",
    "for w in test_words:\n",
    "    preds = predict_word(w)\n",
    "    print(f\"{w:>12s} → {' '.join(preds)}\")\n",
    "\n",
    "\n",
    "cmu = load_cmudict(CMU_DICT_PATH)\n",
    "cmu_dict = dict(cmu)\n",
    "for w in test_words:\n",
    "    if w in cmu_dict:\n",
    "        print(f\"{w}: {' '.join(cmu_dict[w])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_gpu",
   "language": "python",
   "name": "dl_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
