{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c1ef62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 135166 CMUdict entries\n",
      "Training LSTM+CTC model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.4067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 0.2651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.2262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.1628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.1237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.1186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.1113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.1062\n",
      "Training complete, model saved to lstm_ctc_g2p.pth\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# LSTM + CTC Grapheme-to-Phoneme (G2P) model\n",
    "# ===============================================\n",
    "# This model replaces the zero-delay Nettalk baseline with a sequence model\n",
    "# that learns alignment automatically using Connectionist Temporal Classification (CTC).\n",
    "# It follows the setup in the Google G2P paper and can handle variable-length mappings.\n",
    "# ===============================================\n",
    "\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------\n",
    "# Configuration\n",
    "# -------------------\n",
    "CMU_DICT_PATH = \"cmudict.dict.txt\"\n",
    "STRIP_STRESS = True\n",
    "MAX_WORDS = None       # for quick tests, e.g. 20000; set None for full dict\n",
    "BATCH_SIZE = 32\n",
    "EMBED_DIM = 64\n",
    "HIDDEN_DIM = 256\n",
    "EPOCHS = 15\n",
    "LR = 1e-3\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------\n",
    "# Data Loading\n",
    "# -------------------\n",
    "def load_cmudict(path, max_words=None):\n",
    "    entries = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip() or line.startswith(\";;;\"):\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            word = re.sub(r\"\\(\\d+\\)$\", \"\", parts[0]).lower()\n",
    "            phones = parts[1:]\n",
    "            if STRIP_STRESS:\n",
    "                phones = [re.sub(r\"\\d+$\", \"\", p) for p in phones]\n",
    "            entries.append((word, phones))\n",
    "            if max_words and len(entries) >= max_words:\n",
    "                break\n",
    "    return entries\n",
    "\n",
    "entries = load_cmudict(CMU_DICT_PATH, MAX_WORDS)\n",
    "print(f\"Loaded {len(entries)} CMUdict entries\")\n",
    "\n",
    "# Build vocabularies\n",
    "graphemes = sorted({c for w, _ in entries for c in w})\n",
    "phones = sorted({p for _, phs in entries for p in phs})\n",
    "graphemes = [\"<pad>\", \"<s>\", \"</s>\"] + graphemes\n",
    "phones = [\"<blank>\"] + phones  # CTC blank token at index 0\n",
    "\n",
    "char2idx = {c: i for i, c in enumerate(graphemes)}\n",
    "idx2char = {i: c for c, i in char2idx.items()}\n",
    "phone2idx = {p: i for i, p in enumerate(phones)}\n",
    "idx2phone = {i: p for p, i in phone2idx.items()}\n",
    "\n",
    "# -------------------\n",
    "# Dataset\n",
    "# -------------------\n",
    "class G2PCTCDataset(Dataset):\n",
    "    def __init__(self, entries, char2idx, phone2idx):\n",
    "        self.data = []\n",
    "        for word, ph_seq in entries:\n",
    "            x = [char2idx[c] for c in word]\n",
    "            y = [phone2idx[p] for p in ph_seq]\n",
    "            self.data.append((torch.tensor(x), torch.tensor(y)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def collate_batch(batch):\n",
    "    x_seqs, y_seqs = zip(*batch)\n",
    "    x_lens = torch.tensor([len(x) for x in x_seqs])\n",
    "    y_lens = torch.tensor([len(y) for y in y_seqs])\n",
    "    x_pad = pad_sequence(x_seqs, batch_first=False, padding_value=char2idx[\"<pad>\"])\n",
    "    y_cat = torch.cat(y_seqs)\n",
    "    return x_pad, x_lens, y_cat, y_lens\n",
    "\n",
    "# Split into train/dev/test\n",
    "random.seed(42)\n",
    "random.shuffle(entries)\n",
    "n = len(entries)\n",
    "train_entries = entries[: int(0.85 * n)]\n",
    "dev_entries = entries[int(0.85 * n) : int(0.93 * n)]\n",
    "test_entries = entries[int(0.93 * n) :]\n",
    "\n",
    "train_loader = DataLoader(G2PCTCDataset(train_entries, char2idx, phone2idx),\n",
    "                          batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "dev_loader = DataLoader(G2PCTCDataset(dev_entries, char2idx, phone2idx),\n",
    "                        batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(G2PCTCDataset(test_entries, char2idx, phone2idx),\n",
    "                         batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "# -------------------\n",
    "# Model\n",
    "# -------------------\n",
    "class LSTMCTCModel(nn.Module):\n",
    "    def __init__(self, n_chars, embed_dim, hidden_dim, n_phones, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(n_chars, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers,\n",
    "                            batch_first=False, bidirectional=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, n_phones)  # bidirectional\n",
    "    def forward(self, x, lengths):\n",
    "        emb = self.embed(x)  # (T,B,E)\n",
    "        packed = pack_padded_sequence(emb, lengths.cpu(), enforce_sorted=False)\n",
    "        out, _ = self.lstm(packed)\n",
    "        out, _ = torch.nn.utils.rnn.pad_packed_sequence(out)\n",
    "        logits = self.fc(out)  # (T,B,num_phones)\n",
    "        log_probs = torch.log_softmax(logits, dim=2)\n",
    "        return log_probs\n",
    "\n",
    "# -------------------\n",
    "# Training\n",
    "# -------------------\n",
    "model = LSTMCTCModel(len(char2idx), EMBED_DIM, HIDDEN_DIM, len(phone2idx)).to(DEVICE)\n",
    "criterion = nn.CTCLoss(blank=phone2idx[\"<blank>\"], zero_infinity=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "print(\"Training LSTM+CTC model...\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, xlens, yb, ylens in tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False):\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        log_probs = model(xb, xlens)  # (T,B,C)\n",
    "        loss = criterion(log_probs, yb, xlens, ylens)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch} | Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "torch.save({\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"char2idx\": char2idx,\n",
    "    \"phone2idx\": phone2idx,\n",
    "    \"idx2phone\": idx2phone,\n",
    "}, \"lstm_ctc_g2p.pth\")\n",
    "\n",
    "print(\"Training complete, model saved to lstm_ctc_g2p.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f5b16a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      google → G UW G AH L\n",
      "     physics → F IH S IH K S\n",
      "   algorithm → AE L G ER IH DH AH M\n",
      "        data → D EY T AH\n",
      "     chatgpt → CH AE T K P T\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Inference: decode CTC outputs\n",
    "# ==============================\n",
    "\n",
    "def greedy_decode_ctc(log_probs):\n",
    "    \"\"\"Greedy CTC decoding: take argmax over time and collapse repeats/blanks.\"\"\"\n",
    "    indices = log_probs.argmax(dim=2).cpu().numpy().T  # shape (B, T)\n",
    "    preds = []\n",
    "    for seq in indices:\n",
    "        prev = None\n",
    "        out = []\n",
    "        for i in seq:\n",
    "            p = idx2phone[i]\n",
    "            if p == \"<blank>\":\n",
    "                prev = p\n",
    "                continue\n",
    "            if p != prev:\n",
    "                out.append(p)\n",
    "            prev = p\n",
    "        preds.append(out)\n",
    "    return preds\n",
    "\n",
    "# Load model\n",
    "ckpt = torch.load(\"lstm_ctc_g2p.pth\", map_location=DEVICE)\n",
    "model = LSTMCTCModel(len(char2idx), EMBED_DIM, HIDDEN_DIM, len(phone2idx)).to(DEVICE)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval()\n",
    "\n",
    "def predict_g2p(word: str):\n",
    "    seq = torch.tensor([[char2idx.get(c, 0) for c in word.lower()]], dtype=torch.long).T\n",
    "    length = torch.tensor([seq.size(0)], dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        log_probs = model(seq.to(DEVICE), length)  # (T,1,C)\n",
    "    decoded = greedy_decode_ctc(log_probs)[0]\n",
    "    return decoded\n",
    "\n",
    "# Test a few words\n",
    "test_words = [\"google\", \"physics\", \"algorithm\", \"data\", \"chatgpt\"]\n",
    "for w in test_words:\n",
    "    phones_pred = predict_g2p(w)\n",
    "    print(f\"{w:>12s} → {' '.join(phones_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f2be4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word: google\n",
      "Predicted: G UW G AH L\n",
      "Reference: G UW G AH L\n",
      "Phoneme Error Rate (PER): 0.0%\n",
      "\n",
      "Word: physics\n",
      "Predicted: F IH S IH K S\n",
      "Reference: F IH Z IH K S\n",
      "Phoneme Error Rate (PER): 16.7%\n",
      "\n",
      "Word: algorithm\n",
      "Predicted: AE L G ER IH DH AH M\n",
      "Reference: AE L G ER IH DH AH M\n",
      "Phoneme Error Rate (PER): 0.0%\n",
      "\n",
      "Word: data\n",
      "Predicted: D EY T AH\n",
      "Reference: D AE T AH\n",
      "Phoneme Error Rate (PER): 25.0%\n",
      "\n",
      "Word: chatgpt\n",
      "Predicted: CH AE T K P T\n",
      "Reference: <missing>\n",
      "Phoneme Error Rate (PER): 600.0%\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Compare LSTM-CTC predictions with CMUdict\n",
    "# ==========================================\n",
    "\n",
    "# Reload CMUdict (same helper as before)\n",
    "cmu_entries = load_cmudict(CMU_DICT_PATH)\n",
    "cmu_dict = {w: phs for w, phs in cmu_entries}\n",
    "\n",
    "# Pick some test words (must exist in CMUdict)\n",
    "test_words = [\"google\", \"physics\", \"algorithm\", \"data\", \"chatgpt\"]\n",
    "\n",
    "for w in test_words:\n",
    "    pred = predict_g2p(w)\n",
    "    ref = cmu_dict.get(w.lower(), [\"<missing>\"])\n",
    "    print(f\"\\nWord: {w}\")\n",
    "    print(f\"Predicted: {' '.join(pred)}\")\n",
    "    print(f\"Reference: {' '.join(ref)}\")\n",
    "\n",
    "    # --- simple alignment-based accuracy summary ---\n",
    "    # compute edit distance between predicted and reference phonemes\n",
    "    def edit_distance(a, b):\n",
    "        n, m = len(a), len(b)\n",
    "        dp = [[0]*(m+1) for _ in range(n+1)]\n",
    "        for i in range(n+1):\n",
    "            dp[i][0] = i\n",
    "        for j in range(m+1):\n",
    "            dp[0][j] = j\n",
    "        for i in range(1, n+1):\n",
    "            for j in range(1, m+1):\n",
    "                cost = 0 if a[i-1] == b[j-1] else 1\n",
    "                dp[i][j] = min(dp[i-1][j]+1, dp[i][j-1]+1, dp[i-1][j-1]+cost)\n",
    "        return dp[n][m]\n",
    "\n",
    "    ed = edit_distance(pred, ref)\n",
    "    per = ed / max(1, len(ref))\n",
    "    print(f\"Phoneme Error Rate (PER): {per*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a634840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"char_vocab_LSTM.json\", \"w\") as f:\n",
    "    json.dump(char2idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ead2dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved state_dict to nettalk_state_dict_LSTM.pt\n"
     ]
    }
   ],
   "source": [
    "# After training finishes (on your local machine)\n",
    "torch.save(model.state_dict(), \"nettalk_state_dict_LSTM.pt\")\n",
    "print(\"Saved state_dict to nettalk_state_dict_LSTM.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_gpu",
   "language": "python",
   "name": "dl_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
